{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "0d000065-3d93-40a5-9809-8dee0eb1cace",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "Preparación de los datos\n",
    "Este es el paso más crucial para cualquier modelo de machine learning. Aquí debemos:\n",
    "\n",
    "Tratar los datos faltantes: Eliminarlos o imputarlos.\n",
    "Eliminar outliers o aplicar técnicas de transformación.\n",
    "Normalización o escalado de datos: Esto es particularmente importante para modelos como Regresión Lineal o K-Nearest Neighbors (KNN).\n",
    "One-Hot Encoding para variables categóricas: Transformar variables categóricas en variables binarias para que puedan ser utilizadas por los modelos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "0d1cf7cc-5350-4ec0-8ee8-8f0e937dafd6",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "Dividir los datos\n",
    "Es fundamental dividir los datos en train y test. Vamos a utilizar 80% para entrenar y 20% para testear."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "0055349f-abf2-46cb-965f-92733a039a24",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+---------+--------------------+--------+-------------------+---------+----------+--------------+------------------+-----+------------------+\n|InvoiceNo|StockCode|         Description|Quantity|        InvoiceDate|UnitPrice|CustomerID|       Country|           Revenue|Month|             label|\n+---------+---------+--------------------+--------+-------------------+---------+----------+--------------+------------------+-----+------------------+\n|   536365|   85123A|WHITE HANGING HEA...|       6|2010-12-01 08:26:00|     2.55|   17850.0|United Kingdom|15.299999999999999|   12|15.299999999999999|\n|   536365|    71053| WHITE METAL LANTERN|       6|2010-12-01 08:26:00|     3.39|   17850.0|United Kingdom|             20.34|   12|             20.34|\n|   536365|   84406B|CREAM CUPID HEART...|       8|2010-12-01 08:26:00|     2.75|   17850.0|United Kingdom|              22.0|   12|              22.0|\n|   536365|   84029G|KNITTED UNION FLA...|       6|2010-12-01 08:26:00|     3.39|   17850.0|United Kingdom|             20.34|   12|             20.34|\n|   536365|   84029E|RED WOOLLY HOTTIE...|       6|2010-12-01 08:26:00|     3.39|   17850.0|United Kingdom|             20.34|   12|             20.34|\n+---------+---------+--------------------+--------+-------------------+---------+----------+--------------+------------------+-----+------------------+\nonly showing top 5 rows\n\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import col\n",
    "\n",
    "# Crear una sesión de Spark\n",
    "spark = SparkSession.builder.appName(\"ML_Model\").getOrCreate()\n",
    "\n",
    "# Leer los datos del archivo CSV y cargarlos en un DataFrame\n",
    "df = spark.read.csv(\"/FileStore/tables/ecommerce_data_cleaned.csv\", header=True, inferSchema=True)\n",
    "\n",
    "# Crear la columna 'label' desde Revenue\n",
    "df_ml = df.withColumn(\"label\", col(\"Revenue\"))\n",
    "\n",
    "# Mostrar algunas filas\n",
    "df_ml.show(5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "7ee83f4b-b135-4b6d-ae91-87e0a831952d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d94922fd428740bda2cb26828c0fd5b9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading artifacts:   0%|          | 0/40 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "76952152820f4a3f9c64540d2aab0865",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Uploading artifacts:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+------------------+\n|            features|             label|\n+--------------------+------------------+\n|(40,[0,1,2,3],[6....|15.299999999999999|\n|(40,[0,1,2,3],[6....|             20.34|\n|(40,[0,1,2,3],[8....|              22.0|\n|(40,[0,1,2,3],[6....|             20.34|\n|(40,[0,1,2,3],[6....|             20.34|\n+--------------------+------------------+\nonly showing top 5 rows\n\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.feature import StringIndexer, OneHotEncoder, VectorAssembler, StandardScaler\n",
    "from pyspark.ml import Pipeline\n",
    "\n",
    "# Definir las etapas del Pipeline\n",
    "indexer = StringIndexer(inputCol=\"Country\", outputCol=\"CountryIndex\")\n",
    "encoder = OneHotEncoder(inputCol=\"CountryIndex\", outputCol=\"CountryVec\")\n",
    "assembler = VectorAssembler(inputCols=[\"Quantity\", \"UnitPrice\", \"Month\", \"CountryVec\"], outputCol=\"features\")\n",
    "scaler = StandardScaler(inputCol=\"features\", outputCol=\"scaledFeatures\")\n",
    "\n",
    "# Crear el Pipeline con todas las etapas\n",
    "pipeline = Pipeline(stages=[indexer, encoder, assembler, scaler])\n",
    "\n",
    "# Aplicar el pipeline a df_ml (que contiene 'label')\n",
    "df_prepared = pipeline.fit(df_ml).transform(df_ml)\n",
    "\n",
    "# Mostrar las características y etiquetas generadas\n",
    "df_prepared.select(\"features\", \"label\").show(5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "474330e9-ca28-4161-a099-bb33eb2e0f07",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tamaño del conjunto de entrenamiento: 210990\nTamaño del conjunto de prueba: 52468\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Dividir los datos en conjunto de entrenamiento y prueba\n",
    "train_data, test_data = df_prepared.sample(fraction=0.5, seed=42).randomSplit([0.8, 0.2], seed=42)\n",
    "\n",
    "# Verificar el tamaño de los conjuntos\n",
    "print(f\"Tamaño del conjunto de entrenamiento: {train_data.count()}\")\n",
    "print(f\"Tamaño del conjunto de prueba: {test_data.count()}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d97a4db9-6d10-4a0b-8b96-76bdbcb505a5",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.ml.regression import GBTRegressor\n",
    "from pyspark.ml.evaluation import RegressionEvaluator\n",
    "from pyspark.ml.tuning import ParamGridBuilder, CrossValidator\n",
    "\n",
    "# Definir el GBTRegressor\n",
    "gbt = GBTRegressor(featuresCol=\"scaledFeatures\", labelCol=\"label\")\n",
    "\n",
    "# Definir el evaluador (usando RMSE como métrica de evaluación)\n",
    "evaluator = RegressionEvaluator(labelCol=\"label\", predictionCol=\"prediction\", metricName=\"rmse\")\n",
    "\n",
    "# Crear un grid de hiperparámetros para ajustar\n",
    "paramGrid = ParamGridBuilder() \\\n",
    "    .addGrid(gbt.maxDepth, [5, 7]) \\\n",
    "    .addGrid(gbt.maxIter, [10]) \\\n",
    "    .addGrid(gbt.stepSize, [0.1]) \\\n",
    "    .build()\n",
    "\n",
    "# Configurar validación cruzada\n",
    "crossval = CrossValidator(estimator=gbt,\n",
    "                          estimatorParamMaps=paramGrid,\n",
    "                          evaluator=evaluator,\n",
    "                          numFolds=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "2e25db19-43b0-4752-91fb-a1f801cc8f90",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "-Averiguar otro tipo de cross_validator\n",
    "-"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "445e01bb-90c4-4d84-8b00-326a304fbce0",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9b9538039b684def9dd4bfded6f3a138",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading artifacts:   0%|          | 0/35 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "40719b9e8eeb42d481213f5bd65b9714",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Uploading artifacts:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7ae69974247444e48bea39ca35e77398",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading artifacts:   0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "445b3b0645fc4634a44e497e16d4f360",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Uploading artifacts:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Entrenar el modelo con validación cruzada\n",
    "cv_model = crossval.fit(train_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "0b1cf9ea-4c10-401b-b888-2854e7a1a022",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 343.98868608136524\nR²: 0.023475009831276594\n"
     ]
    }
   ],
   "source": [
    "# Predecir en los datos de prueba\n",
    "test_results = cv_model.transform(test_data)\n",
    "\n",
    "# Evaluar el modelo\n",
    "rmse = evaluator.evaluate(test_results)\n",
    "r2_evaluator = RegressionEvaluator(labelCol=\"label\", predictionCol=\"prediction\", metricName=\"r2\")\n",
    "r2 = r2_evaluator.evaluate(test_results)\n",
    "\n",
    "# Mostrar los resultados de la evaluación\n",
    "print(f\"RMSE: {rmse}\")\n",
    "print(f\"R²: {r2}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "e519a69c-3b01-4e08-8027-b78e152c27f8",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "Este código implementa un pipeline de machine learning en PySpark para entrenar un modelo de Gradient Boosted Trees (GBT) con validación cruzada y ajustar los hiperparámetros. Vamos a desglosar cada sección para que comprendas qué está haciendo y cómo impacta en el proceso de construcción del modelo.\n",
    "\n",
    "1. Crear una sesión de Spark y cargar datos\n",
    "python\n",
    "Copiar código\n",
    "spark = SparkSession.builder.appName(\"ML_Model\").getOrCreate()\n",
    "df = spark.read.csv(\"/FileStore/tables/ecommerce_data_cleaned.csv\", header=True, inferSchema=True)\n",
    "Aquí se crea una sesión de Spark (el entorno para ejecutar operaciones distribuidas) y se carga el archivo CSV que contiene los datos limpios de comercio electrónico en un DataFrame llamado df.\n",
    "\n",
    "2. Preparación de la etiqueta (target)\n",
    "python\n",
    "Copiar código\n",
    "df_ml = df.withColumn(\"label\", col(\"Revenue\"))\n",
    "El código crea una nueva columna llamada label a partir de la columna Revenue, que es la variable objetivo (lo que el modelo intentará predecir). Esta columna se utiliza en el modelo como la \"etiqueta\" en un problema de regresión.\n",
    "\n",
    "3. Transformaciones de las características (features)\n",
    "python\n",
    "Copiar código\n",
    "indexer = StringIndexer(inputCol=\"Country\", outputCol=\"CountryIndex\")\n",
    "encoder = OneHotEncoder(inputCol=\"CountryIndex\", outputCol=\"CountryVec\")\n",
    "assembler = VectorAssembler(inputCols=[\"Quantity\", \"UnitPrice\", \"Month\", \"CountryVec\"], outputCol=\"features\")\n",
    "scaler = StandardScaler(inputCol=\"features\", outputCol=\"scaledFeatures\")\n",
    "Esta sección utiliza varias transformaciones para preparar los datos:\n",
    "\n",
    "StringIndexer: Convierte la columna categórica Country en un índice numérico (CountryIndex).\n",
    "OneHotEncoder: Convierte el índice numérico de Country en una representación de one-hot encoding (CountryVec), creando un vector binario para cada categoría.\n",
    "VectorAssembler: Combina varias columnas numéricas como Quantity, UnitPrice, Month y CountryVec en una sola columna features, que el modelo puede usar.\n",
    "StandardScaler: Normaliza los valores de las características para que todas estén en la misma escala, lo que es importante en modelos como GBT.\n",
    "4. Pipeline de transformación\n",
    "python\n",
    "Copiar código\n",
    "pipeline = Pipeline(stages=[indexer, encoder, assembler, scaler])\n",
    "df_prepared = pipeline.fit(df_ml).transform(df_ml)\n",
    "Este código construye un pipeline con las transformaciones anteriores (indexación, codificación, ensamblaje y escalado). El pipeline asegura que todas las etapas de preprocesamiento se ejecuten de manera secuencial. Luego, se transforma el DataFrame original para generar df_prepared, que contiene las columnas features y label.\n",
    "\n",
    "5. División en conjunto de entrenamiento y prueba\n",
    "python\n",
    "Copiar código\n",
    "train_data, test_data = df_prepared.randomSplit([0.8, 0.2], seed=42)\n",
    "Se dividen los datos en un conjunto de entrenamiento (80%) y un conjunto de prueba (20%), lo cual es necesario para evaluar el rendimiento del modelo en datos no vistos.\n",
    "\n",
    "6. Definición y entrenamiento del modelo\n",
    "python\n",
    "Copiar código\n",
    "gbt = GBTRegressor(featuresCol=\"scaledFeatures\", labelCol=\"label\")\n",
    "Se define un regresor GBT (Gradient Boosted Trees) para predecir la columna label usando las características scaledFeatures. GBT es un modelo potente que entrena una serie de árboles de decisión secuenciales, optimizando el error en cada paso.\n",
    "\n",
    "7. Validación cruzada y ajuste de hiperparámetros\n",
    "python\n",
    "Copiar código\n",
    "paramGrid = ParamGridBuilder() \\\n",
    "    .addGrid(gbt.maxDepth, [5, 10]) \\\n",
    "    .addGrid(gbt.maxIter, [10, 20]) \\\n",
    "    .addGrid(gbt.stepSize, [0.1, 0.05]) \\\n",
    "    .build()\n",
    "\n",
    "crossval = CrossValidator(estimator=gbt, \n",
    "                          estimatorParamMaps=paramGrid,\n",
    "                          evaluator=evaluator, \n",
    "                          numFolds=5)\n",
    "Aquí se configura una validación cruzada de 5 pliegues con un grid de hiperparámetros para probar diferentes combinaciones de los parámetros maxDepth, maxIter y stepSize. La validación cruzada ajusta el modelo en diferentes subconjuntos de los datos para encontrar la combinación óptima de estos hiperparámetros.\n",
    "\n",
    "maxDepth: Profundidad máxima de los árboles.\n",
    "maxIter: Número de iteraciones.\n",
    "stepSize: Tasa de aprendizaje.\n",
    "8. Evaluación del modelo\n",
    "python\n",
    "Copiar código\n",
    "test_results = cv_model.transform(test_data)\n",
    "rmse = evaluator.evaluate(test_results)\n",
    "r2 = r2_evaluator.evaluate(test_results)\n",
    "\n",
    "print(f\"RMSE: {rmse}\")\n",
    "print(f\"R²: {r2}\")\n",
    "Se hace una predicción en los datos de prueba con el mejor modelo encontrado por la validación cruzada. Luego, se evalúan los resultados usando dos métricas:\n",
    "\n",
    "RMSE (Error cuadrático medio): mide el error promedio en las predicciones.\n",
    "R² (Coeficiente de determinación): mide qué tan bien el modelo se ajusta a los datos.\n",
    "Conclusión\n",
    "Este código realiza un flujo completo de preparación de datos, creación de un pipeline de procesamiento, entrenamiento de un modelo de GBT, ajuste de hiperparámetros con validación cruzada, y evaluación del modelo en los datos de prueba. Si los valores de RMSE y R² no son satisfactorios, se podrían probar otras características, ajustar mejor los hiperparámetros o considerar otros modelos más adecuados para el conjunto de datos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "c76c2a2e-da77-44a9-b21b-3a9bd28ccf52",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "\n"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "dashboards": [],
   "environmentMetadata": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "gbtboost",
   "widgets": {}
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
